{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Faster Whisper"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **GPU check** (you typically want a V100, P100 or T4)\n",
				"!nvidia-smi -L\n",
				"!nvidia-smi"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **Setup Whisper**\n",
				"%pip install -q deepl srt demucs faster-whisper"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **load Whisper**\n",
				"model_size = \"large-v2\"  # @param [\"tiny\",\"base\",\"small\",\"medium\", \"large-v1\", \"large-v2\"]\n",
				"\n",
				"import torch, torchaudio, os, srt, datetime, json, deepl, urllib.request, faster_whisper\n",
				"from tqdm import tqdm\n",
				"from google.colab import files as g_files, drive as g_drive\n",
				"from demucs.pretrained import get_model as demucs_get_model\n",
				"from demucs.separate import load_track as demucs_load_track\n",
				"from demucs.apply import apply_model as demucs_apply_model\n",
				"\n",
				"DEMUCS_MODEL = demucs_get_model(\"htdemucs\").cuda()\n",
				"WHISPER_MODEL = faster_whisper.WhisperModel(model_size, device=\"cuda\")\n",
				"\n",
				"PUNCT_MATCH = [\"。\", \"、\", \",\", \".\", \"〜\", \"！\", \"!\", \"？\", \"?\", \"-\"]\n",
				"REMOVE_QUOTES = dict.fromkeys(map(ord, '\"„“‟”＂「」'), None)\n",
				"GARBAGE_LIST = [\n",
				"\t\"a\",\n",
				"\t\"aa\",\n",
				"\t\"ah\",\n",
				"\t\"ahh\",\n",
				"\t\"h\",\n",
				"\t\"ha\",\n",
				"\t\"haa\",\n",
				"\t\"hah\",\n",
				"\t\"haha\",\n",
				"\t\"hahaha\",\n",
				"\t\"hm\",\n",
				"\t\"hmm\",\n",
				"\t\"huh\",\n",
				"\t\"m\",\n",
				"\t\"mh\",\n",
				"\t\"mm\",\n",
				"\t\"mmh\",\n",
				"\t\"mmm\",\n",
				"\t\"o\",\n",
				"\t\"oh\",\n",
				"]\n",
				"NEED_CONTEXT_LINES = [\n",
				"\t\"feelsgod\",\n",
				"\t\"godbye\",\n",
				"\t\"godnight\",\n",
				"\t\"thankyou\",\n",
				"]\n",
				"\n",
				"clean_text = lambda text: (text\n",
				"\t.replace(\".\", \"\")\n",
				"\t.replace(\",\", \"\")\n",
				"\t.replace(\":\", \"\")\n",
				"\t.replace(\";\", \"\")\n",
				"\t.replace(\"!\", \"\")\n",
				"\t.replace(\"?\", \"\")\n",
				"\t.replace(\"-\", \" \")\n",
				"\t.replace(\"  \", \" \")\n",
				"\t.replace(\"  \", \" \")\n",
				"\t.replace(\"  \", \" \")\n",
				"\t.lower()\n",
				"\t.replace(\"that feels\", \"feels\")\n",
				"\t.replace(\"it feels\", \"feels\")\n",
				"\t.replace(\"feels good\", \"feelsgood\")\n",
				"\t.replace(\"good bye\", \"goodbye\")\n",
				"\t.replace(\"good night\", \"goodnight\")\n",
				"\t.replace(\"thank you\", \"thankyou\")\n",
				"\t.replace(\"aaaaaa\", \"a\")\n",
				"\t.replace(\"aaaa\", \"a\")\n",
				"\t.replace(\"aa\", \"a\")\n",
				"\t.replace(\"aa\", \"a\")\n",
				"\t.replace(\"mmmmmm\", \"m\")\n",
				"\t.replace(\"mmmm\", \"m\")\n",
				"\t.replace(\"mm\", \"m\")\n",
				"\t.replace(\"mm\", \"m\")\n",
				"\t.replace(\"hhhhhh\", \"h\")\n",
				"\t.replace(\"hhhh\", \"h\")\n",
				"\t.replace(\"hh\", \"h\")\n",
				"\t.replace(\"hh\", \"h\")\n",
				"\t.replace(\"oooooo\", \"o\")\n",
				"\t.replace(\"oooo\", \"o\")\n",
				"\t.replace(\"oo\", \"o\")\n",
				"\t.replace(\"oo\", \"o\")\n",
				")\n",
				"\n",
				"TO_LANGUAGE_CODE = { # from https://github.com/openai/whisper/blob/main/whisper/tokenizer.py\n",
				"\t\"afrikaans\": \"af\",\n",
				"\t\"albanian\": \"sq\",\n",
				"\t\"amharic\": \"am\",\n",
				"\t\"arabic\": \"ar\",\n",
				"\t\"armenian\": \"hy\",\n",
				"\t\"assamese\": \"as\",\n",
				"\t\"azerbaijani\": \"az\",\n",
				"\t\"bashkir\": \"ba\",\n",
				"\t\"basque\": \"eu\",\n",
				"\t\"belarusian\": \"be\",\n",
				"\t\"bengali\": \"bn\",\n",
				"\t\"bosnian\": \"bs\",\n",
				"\t\"breton\": \"br\",\n",
				"\t\"bulgarian\": \"bg\",\n",
				"\t\"burmese\": \"my\",\n",
				"\t\"castilian\": \"es\",\n",
				"\t\"catalan\": \"ca\",\n",
				"\t\"chinese\": \"zh\",\n",
				"\t\"croatian\": \"hr\",\n",
				"\t\"czech\": \"cs\",\n",
				"\t\"danish\": \"da\",\n",
				"\t\"dutch\": \"nl\",\n",
				"\t\"english\": \"en\",\n",
				"\t\"estonian\": \"et\",\n",
				"\t\"faroese\": \"fo\",\n",
				"\t\"finnish\": \"fi\",\n",
				"\t\"flemish\": \"nl\",\n",
				"\t\"french\": \"fr\",\n",
				"\t\"galician\": \"gl\",\n",
				"\t\"georgian\": \"ka\",\n",
				"\t\"german\": \"de\",\n",
				"\t\"greek\": \"el\",\n",
				"\t\"gujarati\": \"gu\",\n",
				"\t\"haitian creole\": \"ht\",\n",
				"\t\"haitian\": \"ht\",\n",
				"\t\"hausa\": \"ha\",\n",
				"\t\"hawaiian\": \"haw\",\n",
				"\t\"hebrew\": \"he\",\n",
				"\t\"hindi\": \"hi\",\n",
				"\t\"hungarian\": \"hu\",\n",
				"\t\"icelandic\": \"is\",\n",
				"\t\"indonesian\": \"id\",\n",
				"\t\"italian\": \"it\",\n",
				"\t\"japanese\": \"ja\",\n",
				"\t\"javanese\": \"jw\",\n",
				"\t\"kannada\": \"kn\",\n",
				"\t\"kazakh\": \"kk\",\n",
				"\t\"khmer\": \"km\",\n",
				"\t\"korean\": \"ko\",\n",
				"\t\"lao\": \"lo\",\n",
				"\t\"latin\": \"la\",\n",
				"\t\"latvian\": \"lv\",\n",
				"\t\"letzeburgesch\": \"lb\",\n",
				"\t\"lingala\": \"ln\",\n",
				"\t\"lithuanian\": \"lt\",\n",
				"\t\"luxembourgish\": \"lb\",\n",
				"\t\"macedonian\": \"mk\",\n",
				"\t\"malagasy\": \"mg\",\n",
				"\t\"malay\": \"ms\",\n",
				"\t\"malayalam\": \"ml\",\n",
				"\t\"maltese\": \"mt\",\n",
				"\t\"maori\": \"mi\",\n",
				"\t\"marathi\": \"mr\",\n",
				"\t\"moldavian\": \"ro\",\n",
				"\t\"moldovan\": \"ro\",\n",
				"\t\"mongolian\": \"mn\",\n",
				"\t\"myanmar\": \"my\",\n",
				"\t\"nepali\": \"ne\",\n",
				"\t\"norwegian\": \"no\",\n",
				"\t\"nynorsk\": \"nn\",\n",
				"\t\"occitan\": \"oc\",\n",
				"\t\"panjabi\": \"pa\",\n",
				"\t\"pashto\": \"ps\",\n",
				"\t\"persian\": \"fa\",\n",
				"\t\"polish\": \"pl\",\n",
				"\t\"portuguese\": \"pt\",\n",
				"\t\"punjabi\": \"pa\",\n",
				"\t\"pushto\": \"ps\",\n",
				"\t\"romanian\": \"ro\",\n",
				"\t\"russian\": \"ru\",\n",
				"\t\"sanskrit\": \"sa\",\n",
				"\t\"serbian\": \"sr\",\n",
				"\t\"shona\": \"sn\",\n",
				"\t\"sindhi\": \"sd\",\n",
				"\t\"sinhala\": \"si\",\n",
				"\t\"sinhalese\": \"si\",\n",
				"\t\"slovak\": \"sk\",\n",
				"\t\"slovenian\": \"sl\",\n",
				"\t\"somali\": \"so\",\n",
				"\t\"spanish\": \"es\",\n",
				"\t\"sundanese\": \"su\",\n",
				"\t\"swahili\": \"sw\",\n",
				"\t\"swedish\": \"sv\",\n",
				"\t\"tagalog\": \"tl\",\n",
				"\t\"tajik\": \"tg\",\n",
				"\t\"tamil\": \"ta\",\n",
				"\t\"tatar\": \"tt\",\n",
				"\t\"telugu\": \"te\",\n",
				"\t\"thai\": \"th\",\n",
				"\t\"tibetan\": \"bo\",\n",
				"\t\"turkish\": \"tr\",\n",
				"\t\"turkmen\": \"tk\",\n",
				"\t\"ukrainian\": \"uk\",\n",
				"\t\"urdu\": \"ur\",\n",
				"\t\"uzbek\": \"uz\",\n",
				"\t\"valencian\": \"ca\",\n",
				"\t\"vietnamese\": \"vi\",\n",
				"\t\"welsh\": \"cy\",\n",
				"\t\"yiddish\": \"yi\",\n",
				"\t\"yoruba\": \"yo\",\n",
				"}"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **Mount Google Drive** (skip this if your audio file isn't stored there)\n",
				"g_drive.mount(\"drive\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **Upload audio file to Colab** (optional) <br>\n",
				"#@markdown If this step fails, or is very slow, try one of these options:\n",
				"#@markdown  - Drag your file into the Files sidebar, and set audio_path to the filename\n",
				"#@markdown  - OR upload it to Google Drive, mount it, and set audio_path to the absolute path\n",
				"#@markdown  - OR upload it to a service like Litterbox, and set audio_path to the URL\n",
				"\n",
				"gfiles = g_files.upload()\n",
				"if len(gfiles) > 0:\n",
				"\tuploaded_file = list(gfiles)[0]\n",
				"\tprint(\"Upload complete\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **Run Whisper**\n",
				"\n",
				"#@markdown Required settings:\n",
				"audio_path = \"input.mp3\"  # @param {type:\"string\"}\n",
				"#@markdown >*path can be a file on drive or a link*\n",
				"language = \"japanese\"  # @param {type:\"string\"}\n",
				"translation_mode = \"transcription + translation\"  # @param [\"transcription only\", \"transcription + translation\", \"transcription + translation with DeepL\"]\n",
				"#@markdown if using DeepL then add auth key:\n",
				"deepl_authkey = \"\"  # @param {type:\"string\"}\n",
				"deepl_target_lang = \"EN-US\"  # @param {type:\"string\"}\n",
				"#@markdown SileroVAD settings:\n",
				"vad_threshold = 0.4  # @param {type:\"number\"}\n",
				"chunk_duration = 15.0  # @param {type:\"number\"}\n",
				"#@markdown enable this setting below for audio with duration >1h requires lots of RAM and crashes Colab\n",
				"vocals_extraction = False  # @param {type:\"boolean\"}\n",
				"#@markdown 2 settings below should not be changed except for very edge cases\n",
				"condition_on_previous_text = True  # @param {type:\"boolean\"}\n",
				"initial_prompt = \"\"  # @param {type:\"string\"}\n",
				"\n",
				"# some sanity checks\n",
				"assert vad_threshold >= 0.01\n",
				"assert chunk_duration >= 0.1\n",
				"assert audio_path != \"\"\n",
				"assert language != \"\"\n",
				"language = language.lower()\n",
				"assert language in TO_LANGUAGE_CODE, \"invalid language\"\n",
				"\n",
				"if translation_mode == \"transcription + translation\":\n",
				"\ttask = \"translate\"\n",
				"\trun_deepl = False\n",
				"elif translation_mode == \"transcription + translation with DeepL\":\n",
				"\ttask = \"transcribe\"\n",
				"\trun_deepl = True\n",
				"elif translation_mode == \"transcription only\":\n",
				"\ttask = \"transcribe\"\n",
				"\trun_deepl = False\n",
				"else:\n",
				"\traise ValueError(\"Invalid translation mode\")\n",
				"\n",
				"if initial_prompt.strip() == \"\":\n",
				"\tinitial_prompt = None\n",
				"\n",
				"if \"http://\" in audio_path or \"https://\" in audio_path:\n",
				"\tprint(\"Downloading audio …\")\n",
				"\turllib.request.urlretrieve(audio_path, \"input_file\")\n",
				"\taudio_path = \"input_file\"\n",
				"else:\n",
				"\tif not os.path.exists(audio_path):\n",
				"\t\ttry:\n",
				"\t\t\taudio_path = uploaded_file\n",
				"\t\t\tif not os.path.exists(audio_path):\n",
				"\t\t\t\traise ValueError(\"Input audio not found. Is your audio_path correct?\")\n",
				"\t\texcept:\n",
				"\t\t\traise ValueError(\"Input audio not found. Did you upload a file?\")\n",
				"\n",
				"audiofilebasename = os.path.splitext(audio_path)[0]\n",
				"out_path = audiofilebasename + \".srt\"\n",
				"out_path_pre = audiofilebasename + \"_Untranslated.srt\"\n",
				"\n",
				"if vocals_extraction:\n",
				"\tprint(\"Separating vocals …\")\n",
				"\traw_audio = demucs_load_track(audio_path, DEMUCS_MODEL.audio_channels, DEMUCS_MODEL.samplerate)\n",
				"\t# should not be on GPU because sometimes not enough VRAM\n",
				"\tif raw_audio.dim() == 1:\n",
				"\t\traw_audio = raw_audio[None, None].repeat_interleave(2, -2)\n",
				"\telif raw_audio.shape[-2] == 1:\n",
				"\t\traw_audio = raw_audio.repeat_interleave(2, -2)\n",
				"\telif raw_audio.dim() < 3:\n",
				"\t\traw_audio = raw_audio[None]\n",
				"\tdemucs_extract = demucs_apply_model(DEMUCS_MODEL, raw_audio, device=\"cuda\", split=True, overlap=.25)\n",
				"\ttorch.cuda.empty_cache()\n",
				"\tdemucs_res = demucs_extract[0, DEMUCS_MODEL.sources.index(\"vocals\")].mean(0)[None]\n",
				"\taudio_path = audiofilebasename + \".vocals.wav\"\n",
				"\ttorchaudio.save(audio_path, demucs_res, DEMUCS_MODEL.samplerate)\n",
				"\n",
				"print(\"Running Whisper … PLEASE WAIT\")\n",
				"segments, info = WHISPER_MODEL.transcribe(\n",
				"\taudio_path, task=task,\n",
				"\tlanguage=TO_LANGUAGE_CODE[language],\n",
				"\tcondition_on_previous_text=condition_on_previous_text,\n",
				"\tinitial_prompt=initial_prompt,\n",
				"\tvad_filter=True,\n",
				"\tvad_parameters=dict(threshold=vad_threshold, max_speech_duration_s=chunk_duration),\n",
				")\n",
				"\n",
				"subs = []\n",
				"segment_info = []\n",
				"timestamps = 0.0  # for progress bar\n",
				"\n",
				"with tqdm(total=info.duration, unit=\" audio seconds\") as pbar:\n",
				"\tfor i, seg in enumerate(segments, start=1):\n",
				"\t\t# Keep segment info for debugging\n",
				"\t\tsegment_info.append(seg)\n",
				"\t\t# Add to SRT list\n",
				"\t\tsubs.append(srt.Subtitle(\n",
				"\t\t\tindex=i,\n",
				"\t\t\tstart=datetime.timedelta(seconds=seg.start),\n",
				"\t\t\tend=datetime.timedelta(seconds=seg.end),\n",
				"\t\t\tcontent=seg.text.lstrip(),\n",
				"\t\t))\n",
				"\t\tpbar.update(seg.end - timestamps)\n",
				"\t\ttimestamps = seg.end\n",
				"\tif timestamps < info.duration:\n",
				"\t\tpbar.update(info.duration - timestamps)\n",
				"\n",
				"# for debugging only\n",
				"with open(\"segment_info.debug.json\", mode=\"w\", encoding=\"utf8\") as f:\n",
				"\tjson.dump(segment_info, f, indent=4)\n",
				"\n",
				"# DeepL translation\n",
				"translate_error = False\n",
				"if run_deepl:\n",
				"\tprint(\"Translating …\")\n",
				"\twith open(out_path_pre, \"w\", encoding=\"utf8\") as f:\n",
				"\t\tf.write(srt.compose(subs))\n",
				"\tprint(\"(Untranslated subs saved to\", out_path_pre, \")\")\n",
				"\n",
				"\tlines = []\n",
				"\tfor i in range(len(subs)):\n",
				"\t\tif language == \"japanese\":\n",
				"\t\t\tif subs[i].content[-1] not in PUNCT_MATCH:\n",
				"\t\t\t\tsubs[i].content += \"。\"\n",
				"\t\t\tsubs[i].content = \"「\" + subs[i].content + \"」\"\n",
				"\t\telse:\n",
				"\t\t\tif subs[i].content[-1] not in PUNCT_MATCH:\n",
				"\t\t\t\tsubs[i].content += \".\"\n",
				"\t\t\tsubs[i].content = '\"' + subs[i].content + '\"'\n",
				"\tfor i in range(len(subs)):\n",
				"\t\tlines.append(subs[i].content)\n",
				"\n",
				"\tgrouped_lines = []\n",
				"\tenglish_lines = []\n",
				"\tfor i, l in enumerate(lines):\n",
				"\t\tif i % 30 == 0:\n",
				"\t\t\t# Split lines into smaller groups, to prevent error 413\n",
				"\t\t\tgrouped_lines.append([])\n",
				"\t\t\tif i != 0:\n",
				"\t\t\t\t# Include previous 3 lines, to preserve context between splits\n",
				"\t\t\t\tgrouped_lines[-1].extend(grouped_lines[-2][-3:])\n",
				"\t\tgrouped_lines[-1].append(l.strip())\n",
				"\t\t\n",
				"\ttry:\n",
				"\t\ttranslator = deepl.Translator(deepl_authkey)\n",
				"\t\tfor i, n in enumerate(tqdm(grouped_lines)):\n",
				"\t\t\tx = [\"\\n\".join(n).strip()]\n",
				"\t\t\tif language == \"japanese\":\n",
				"\t\t\t\tresult = translator.translate_text(x, source_lang=\"JA\", target_lang=deepl_target_lang)\n",
				"\t\t\telse:\n",
				"\t\t\t\tresult = translator.translate_text(x, target_lang=deepl_target_lang)\n",
				"\t\t\tenglish_tl = result[0].text.strip().splitlines()\n",
				"\t\t\tassert len(english_tl) == len(n), f\"Invalid translation line count ({len(english_tl)} vs {len(n)})\"\n",
				"\t\t\tif i != 0:\n",
				"\t\t\t\tenglish_tl = english_tl[3:]\n",
				"\t\t\tfor e in english_tl:\n",
				"\t\t\t\tenglish_lines.append(\n",
				"\t\t\t\t\te.strip().translate(REMOVE_QUOTES).replace(\"’\", \"'\")\n",
				"\t\t\t\t)\n",
				"\t\tfor i, e in enumerate(english_lines):\n",
				"\t\t\tsubs[i].content = e\n",
				"\texcept Exception as e:\n",
				"\t\tprint(\"DeepL translation error:\", e)\n",
				"\t\tprint(\"(downloading untranslated version instead)\")\n",
				"\t\ttranslate_error = True\n",
				"\n",
				"# Write SRT file\n",
				"if translate_error:\n",
				"\tg_files.download(out_path_pre)\n",
				"else:\n",
				"\t# Removal of garbage lines\n",
				"\tclean_subs = []\n",
				"\tlast_line_garbage = False\n",
				"\tfor i in range(len(subs)):\n",
				"\t\tc = clean_text(subs[i].content)\n",
				"\t\tis_garbage = True\n",
				"\t\tfor w in c.split(\" \"):\n",
				"\t\t\tw_tmp = w.strip()\n",
				"\t\t\tif w_tmp == \"\":\n",
				"\t\t\t\tcontinue\n",
				"\t\t\tif w_tmp in GARBAGE_LIST:\n",
				"\t\t\t\tcontinue\n",
				"\t\t\telif w_tmp in NEED_CONTEXT_LINES and last_line_garbage:\n",
				"\t\t\t\tcontinue\n",
				"\t\t\telse:\n",
				"\t\t\t\tis_garbage = False\n",
				"\t\t\t\tbreak\n",
				"\t\tif not is_garbage:\n",
				"\t\t\tclean_subs.append(subs[i])\n",
				"\t\tlast_line_garbage = is_garbage\n",
				"\twith open(out_path, mode=\"w\", encoding=\"utf8\") as f:\n",
				"\t\tf.write(srt.compose(clean_subs))\n",
				"\tprint(\"\\nDone! Subs written to\", out_path)\n",
				"\tprint(\"Downloading SRT file:\")\n",
				"\tg_files.download(out_path)"
			]
		}
	],
	"metadata": {
		"accelerator": "GPU",
		"colab": {
			"private_outputs": true,
			"provenance": []
		},
		"gpuClass": "standard",
		"kernelspec": {
			"display_name": "Python 3",
			"name": "python3"
		},
		"language_info": {
			"name": "python"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 0
}
