{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Whisper with huggingface `transformers`"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **GPU check** (free tier T4, paid tier V100 or A100, if error then u must enable gpu session)\n",
				"!nvidia-smi -L"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **Setup Whisper**\n",
				"%pip install -q flash-attn deepl srt\n",
				"\n",
				"PUNCT_MATCH = [\"。\", \"、\", \",\", \".\", \"〜\", \"！\", \"!\", \"？\", \"?\", \"-\"]\n",
				"REMOVE_QUOTES = dict.fromkeys(map(ord, '\"„“‟”＂「」'), None)\n",
				"\n",
				"MEDIA_EXT = [\n",
				"\t\".3gp\",\n",
				"\t\".aac\",\n",
				"\t\".ac3\",\n",
				"\t\".aif\",\n",
				"\t\".aifc\",\n",
				"\t\".aiff\",\n",
				"\t\".amr\",\n",
				"\t\".ape\",\n",
				"\t\".asf\",\n",
				"\t\".asx\",\n",
				"\t\".au\",\n",
				"\t\".avi\",\n",
				"\t\".bdmv\",\n",
				"\t\".bwf\",\n",
				"\t\".caf\",\n",
				"\t\".dat\",\n",
				"\t\".dts\",\n",
				"\t\".dtshd\",\n",
				"\t\".eac3\",\n",
				"\t\".eb3\",\n",
				"\t\".ec3\",\n",
				"\t\".f4v\",\n",
				"\t\".flac\",\n",
				"\t\".fli\",\n",
				"\t\".flv\",\n",
				"\t\".l16\",\n",
				"\t\".m1a\",\n",
				"\t\".m2a\",\n",
				"\t\".m2ts\",\n",
				"\t\".m4a\",\n",
				"\t\".m4v\",\n",
				"\t\".mid\",\n",
				"\t\".mka\",\n",
				"\t\".mkv\",\n",
				"\t\".mlp\",\n",
				"\t\".mod\",\n",
				"\t\".mov\",\n",
				"\t\".mp1\",\n",
				"\t\".mp2\",\n",
				"\t\".mp3\",\n",
				"\t\".mp4\",\n",
				"\t\".mpa\",\n",
				"\t\".mpc\",\n",
				"\t\".mpeg\",\n",
				"\t\".mpg\",\n",
				"\t\".ofr\",\n",
				"\t\".oga\",\n",
				"\t\".ogg\",\n",
				"\t\".opus\",\n",
				"\t\".pcm\",\n",
				"\t\".qt\",\n",
				"\t\".ra\",\n",
				"\t\".ram\",\n",
				"\t\".rm\",\n",
				"\t\".snd\",\n",
				"\t\".spx\",\n",
				"\t\".stm\",\n",
				"\t\".tak\",\n",
				"\t\".thd\",\n",
				"\t\".ts\",\n",
				"\t\".tta\",\n",
				"\t\".vob\",\n",
				"\t\".voc\",\n",
				"\t\".vqf\",\n",
				"\t\".wav\",\n",
				"\t\".wave\",\n",
				"\t\".webm\",\n",
				"\t\".wma\",\n",
				"\t\".wmv\",\n",
				"\t\".wv\",\n",
				"]\n",
				"\n",
				"GARBAGE_LIST = [\n",
				"\t\"a\",\n",
				"\t\"aa\",\n",
				"\t\"ah\",\n",
				"\t\"ahh\",\n",
				"\t\"h\",\n",
				"\t\"ha\",\n",
				"\t\"haa\",\n",
				"\t\"hah\",\n",
				"\t\"haha\",\n",
				"\t\"hahaha\",\n",
				"\t\"hm\",\n",
				"\t\"hmm\",\n",
				"\t\"huh\",\n",
				"\t\"m\",\n",
				"\t\"mh\",\n",
				"\t\"mm\",\n",
				"\t\"mmh\",\n",
				"\t\"mmm\",\n",
				"\t\"o\",\n",
				"\t\"oh\",\n",
				"]\n",
				"\n",
				"NEED_CONTEXT_LINES = [\n",
				"\t\"feelsgod\",\n",
				"\t\"godbye\",\n",
				"\t\"godnight\",\n",
				"\t\"thankyou\",\n",
				"]\n",
				"\n",
				"clean_text = lambda text: (text\n",
				"\t.replace(\".\", \"\")\n",
				"\t.replace(\",\", \"\")\n",
				"\t.replace(\":\", \"\")\n",
				"\t.replace(\";\", \"\")\n",
				"\t.replace(\"!\", \"\")\n",
				"\t.replace(\"?\", \"\")\n",
				"\t.replace(\"-\", \" \")\n",
				"\t.replace(\"  \", \" \")\n",
				"\t.replace(\"  \", \" \")\n",
				"\t.replace(\"  \", \" \")\n",
				"\t.lower()\n",
				"\t.replace(\"that feels\", \"feels\")\n",
				"\t.replace(\"it feels\", \"feels\")\n",
				"\t.replace(\"feels good\", \"feelsgood\")\n",
				"\t.replace(\"good bye\", \"goodbye\")\n",
				"\t.replace(\"good night\", \"goodnight\")\n",
				"\t.replace(\"thank you\", \"thankyou\")\n",
				"\t.replace(\"aaaaaa\", \"a\")\n",
				"\t.replace(\"aaaa\", \"a\")\n",
				"\t.replace(\"aa\", \"a\")\n",
				"\t.replace(\"aa\", \"a\")\n",
				"\t.replace(\"mmmmmm\", \"m\")\n",
				"\t.replace(\"mmmm\", \"m\")\n",
				"\t.replace(\"mm\", \"m\")\n",
				"\t.replace(\"mm\", \"m\")\n",
				"\t.replace(\"hhhhhh\", \"h\")\n",
				"\t.replace(\"hhhh\", \"h\")\n",
				"\t.replace(\"hh\", \"h\")\n",
				"\t.replace(\"hh\", \"h\")\n",
				"\t.replace(\"oooooo\", \"o\")\n",
				"\t.replace(\"oooo\", \"o\")\n",
				"\t.replace(\"oo\", \"o\")\n",
				"\t.replace(\"oo\", \"o\")\n",
				")\n",
				"\n",
				"TO_LANGUAGE_CODE = { # from https://github.com/openai/whisper/blob/main/whisper/tokenizer.py\n",
				"\t\"afrikaans\": \"af\",\n",
				"\t\"albanian\": \"sq\",\n",
				"\t\"amharic\": \"am\",\n",
				"\t\"arabic\": \"ar\",\n",
				"\t\"armenian\": \"hy\",\n",
				"\t\"assamese\": \"as\",\n",
				"\t\"azerbaijani\": \"az\",\n",
				"\t\"bashkir\": \"ba\",\n",
				"\t\"basque\": \"eu\",\n",
				"\t\"belarusian\": \"be\",\n",
				"\t\"bengali\": \"bn\",\n",
				"\t\"bosnian\": \"bs\",\n",
				"\t\"breton\": \"br\",\n",
				"\t\"bulgarian\": \"bg\",\n",
				"\t\"burmese\": \"my\",\n",
				"\t\"castilian\": \"es\",\n",
				"\t\"catalan\": \"ca\",\n",
				"\t\"chinese\": \"zh\",\n",
				"\t\"croatian\": \"hr\",\n",
				"\t\"czech\": \"cs\",\n",
				"\t\"danish\": \"da\",\n",
				"\t\"dutch\": \"nl\",\n",
				"\t\"english\": \"en\",\n",
				"\t\"estonian\": \"et\",\n",
				"\t\"faroese\": \"fo\",\n",
				"\t\"finnish\": \"fi\",\n",
				"\t\"flemish\": \"nl\",\n",
				"\t\"french\": \"fr\",\n",
				"\t\"galician\": \"gl\",\n",
				"\t\"georgian\": \"ka\",\n",
				"\t\"german\": \"de\",\n",
				"\t\"greek\": \"el\",\n",
				"\t\"gujarati\": \"gu\",\n",
				"\t\"haitian creole\": \"ht\",\n",
				"\t\"haitian\": \"ht\",\n",
				"\t\"hausa\": \"ha\",\n",
				"\t\"hawaiian\": \"haw\",\n",
				"\t\"hebrew\": \"he\",\n",
				"\t\"hindi\": \"hi\",\n",
				"\t\"hungarian\": \"hu\",\n",
				"\t\"icelandic\": \"is\",\n",
				"\t\"indonesian\": \"id\",\n",
				"\t\"italian\": \"it\",\n",
				"\t\"japanese\": \"ja\",\n",
				"\t\"javanese\": \"jw\",\n",
				"\t\"kannada\": \"kn\",\n",
				"\t\"kazakh\": \"kk\",\n",
				"\t\"khmer\": \"km\",\n",
				"\t\"korean\": \"ko\",\n",
				"\t\"lao\": \"lo\",\n",
				"\t\"latin\": \"la\",\n",
				"\t\"latvian\": \"lv\",\n",
				"\t\"letzeburgesch\": \"lb\",\n",
				"\t\"lingala\": \"ln\",\n",
				"\t\"lithuanian\": \"lt\",\n",
				"\t\"luxembourgish\": \"lb\",\n",
				"\t\"macedonian\": \"mk\",\n",
				"\t\"malagasy\": \"mg\",\n",
				"\t\"malay\": \"ms\",\n",
				"\t\"malayalam\": \"ml\",\n",
				"\t\"maltese\": \"mt\",\n",
				"\t\"maori\": \"mi\",\n",
				"\t\"marathi\": \"mr\",\n",
				"\t\"moldavian\": \"ro\",\n",
				"\t\"moldovan\": \"ro\",\n",
				"\t\"mongolian\": \"mn\",\n",
				"\t\"myanmar\": \"my\",\n",
				"\t\"nepali\": \"ne\",\n",
				"\t\"norwegian\": \"no\",\n",
				"\t\"nynorsk\": \"nn\",\n",
				"\t\"occitan\": \"oc\",\n",
				"\t\"panjabi\": \"pa\",\n",
				"\t\"pashto\": \"ps\",\n",
				"\t\"persian\": \"fa\",\n",
				"\t\"polish\": \"pl\",\n",
				"\t\"portuguese\": \"pt\",\n",
				"\t\"punjabi\": \"pa\",\n",
				"\t\"pushto\": \"ps\",\n",
				"\t\"romanian\": \"ro\",\n",
				"\t\"russian\": \"ru\",\n",
				"\t\"sanskrit\": \"sa\",\n",
				"\t\"serbian\": \"sr\",\n",
				"\t\"shona\": \"sn\",\n",
				"\t\"sindhi\": \"sd\",\n",
				"\t\"sinhala\": \"si\",\n",
				"\t\"sinhalese\": \"si\",\n",
				"\t\"slovak\": \"sk\",\n",
				"\t\"slovenian\": \"sl\",\n",
				"\t\"somali\": \"so\",\n",
				"\t\"spanish\": \"es\",\n",
				"\t\"sundanese\": \"su\",\n",
				"\t\"swahili\": \"sw\",\n",
				"\t\"swedish\": \"sv\",\n",
				"\t\"tagalog\": \"tl\",\n",
				"\t\"tajik\": \"tg\",\n",
				"\t\"tamil\": \"ta\",\n",
				"\t\"tatar\": \"tt\",\n",
				"\t\"telugu\": \"te\",\n",
				"\t\"thai\": \"th\",\n",
				"\t\"tibetan\": \"bo\",\n",
				"\t\"turkish\": \"tr\",\n",
				"\t\"turkmen\": \"tk\",\n",
				"\t\"ukrainian\": \"uk\",\n",
				"\t\"urdu\": \"ur\",\n",
				"\t\"uzbek\": \"uz\",\n",
				"\t\"valencian\": \"ca\",\n",
				"\t\"vietnamese\": \"vi\",\n",
				"\t\"welsh\": \"cy\",\n",
				"\t\"yiddish\": \"yi\",\n",
				"\t\"yoruba\": \"yo\",\n",
				"}"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"# weird error with huggingface\n",
				"from huggingface_hub.utils import _runtime\n",
				"_runtime._is_google_colab = False\n",
				"\n",
				"import os, srt, json, torch\n",
				"from datetime import timedelta\n",
				"from transformers import pipeline\n",
				"from google.colab import files as g_files, drive as g_drive\n",
				"\n",
				"#@markdown **load Whisper**\n",
				"model_size = \"large-v2\"  # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\", \"large-v3\"]\n",
				"\n",
				"SILERO_SAMPLING_RATE = 16000  # Silero VAD operating value\n",
				"SILERO_MODEL, (silero_get_speech_timestamps, silero_save_audio, silero_read_audio, _, silero_collect_chunks) = torch.hub.load(\n",
				"\trepo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\", onnx=False\n",
				")\n",
				"\n",
				"WHISPER_MODEL = pipeline(\n",
				"\ttask=\"automatic-speech-recognition\",\n",
				"\tmodel=\"openai/whisper-\" + model_size,\n",
				"\tdevice=\"cuda:0\",\n",
				"\ttorch_dtype=torch.float16,\n",
				"\tchunk_length_s=30, # if not precised then only generate as much as `max_new_tokens`\n",
				"\tbatch_size=24,\n",
				"\tgenerate_kwargs={\"num_beams\": 5, \"attn_implementation\": \"flash_attention_2\"}\n",
				")\n",
				"\n",
				"def my_transcribe_func(audio_path: str, task: str, language: str) -> None:\n",
				"\taudiofilebasename = os.path.splitext(audio_path)[0]\n",
				"\tout_path = audiofilebasename + \".srt\"\n",
				"\n",
				"\tsilero_wav = silero_read_audio(audio_path, sampling_rate=SILERO_SAMPLING_RATE)  # SileroVAD operate on mono channel at 16 kHz\n",
				"\tsilero_speech_timestamps = silero_get_speech_timestamps(silero_wav, SILERO_MODEL, sampling_rate=SILERO_SAMPLING_RATE)\n",
				"\taudio_wav = silero_collect_chunks(silero_speech_timestamps, silero_wav).numpy()\n",
				"\n",
				"\tprint(\"Running Whisper … PLEASE WAIT\")\n",
				"\tresult = WHISPER_MODEL(\n",
				"\t\taudio_wav,\n",
				"\t\treturn_timestamps=True,\n",
				"\t\tgenerate_kwargs={\n",
				"\t\t\t\"language\": TO_LANGUAGE_CODE[language],\n",
				"\t\t\t\"task\": task,\n",
				"\t\t}\n",
				"\t)\n",
				"\n",
				"\tsubs = []\n",
				"\tsegment_info = []\n",
				"\n",
				"\tfor i, chunk in enumerate(result[\"chunks\"], start=1):\n",
				"\t\t# Keep segment info for debugging\n",
				"\t\tsegment_info.append(chunk)\n",
				"\t\t# Add to SRT list\n",
				"\t\tsubs.append(srt.Subtitle(\n",
				"\t\t\tindex=i,\n",
				"\t\t\tstart=timedelta(seconds=chunk[\"timestamp\"][0]),\n",
				"\t\t\tend=timedelta(seconds=chunk[\"timestamp\"][1]),\n",
				"\t\t\tcontent=chunk[\"text\"].strip(),\n",
				"\t\t))\n",
				"\n",
				"\t# for debugging only\n",
				"\twith open(audiofilebasename + \".debug.json\", mode=\"w\", encoding=\"utf8\") as f:\n",
				"\t\tjson.dump(segment_info, f, indent=\"\\t\")\n",
				"\n",
				"\t# Removal of garbage lines\n",
				"\tclean_subs = []\n",
				"\tlast_line_garbage = False\n",
				"\tfor i in range(len(subs)):\n",
				"\t\tc = clean_text(subs[i].content)\n",
				"\t\tis_garbage = True\n",
				"\t\tfor w in c.split(\" \"):\n",
				"\t\t\tw_tmp = w.strip()\n",
				"\t\t\tif w_tmp == \"\":\n",
				"\t\t\t\tcontinue\n",
				"\t\t\tif w_tmp in GARBAGE_LIST:\n",
				"\t\t\t\tcontinue\n",
				"\t\t\telif w_tmp in NEED_CONTEXT_LINES and last_line_garbage:\n",
				"\t\t\t\tcontinue\n",
				"\t\t\telse:\n",
				"\t\t\t\tis_garbage = False\n",
				"\t\t\t\tbreak\n",
				"\t\tif not is_garbage:\n",
				"\t\t\tclean_subs.append(subs[i])\n",
				"\t\tlast_line_garbage = is_garbage\n",
				"\twith open(out_path, mode=\"w\", encoding=\"utf8\") as f:\n",
				"\t\tf.write(srt.compose(clean_subs))\n",
				"\tprint(\"\\nDone! Subs written to\", out_path)\n",
				"\tprint(\"Downloading SRT file:\")\n",
				"\tg_files.download(out_path)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **Mount Google Drive** (skip this if your audio file isn't stored there)\n",
				"g_drive.mount(\"drive\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **Upload audio file to Colab** (optional) <br>\n",
				"#@markdown If this step fails, or is very slow, try one of these options:\n",
				"#@markdown  - Drag your file into the Files sidebar, and set audio_path to the filename\n",
				"#@markdown  - OR upload it to Google Drive, mount it, and set audio_path to the absolute path\n",
				"\n",
				"gfiles = g_files.upload()\n",
				"if len(gfiles) > 0:\n",
				"\tuploaded_file = list(gfiles)[0]\n",
				"\tprint(\"Upload complete\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"cellView": "form"
			},
			"outputs": [],
			"source": [
				"#@markdown **Run Whisper**\n",
				"\n",
				"audio_path = \"wu16rnkF8II.opus\"  # @param {type:\"string\"}\n",
				"#@markdown >*path can be a file or a folder contain audio files*\n",
				"language = \"english\"  # @param {type:\"string\"}\n",
				"translation_mode = \"transcription only\"  # @param [\"transcription only\", \"transcription + translation\"]\n",
				"\n",
				"# some sanity checks\n",
				"assert audio_path != \"\"\n",
				"assert language != \"\"\n",
				"language = language.lower()\n",
				"assert language in TO_LANGUAGE_CODE, \"invalid language\"\n",
				"\n",
				"if translation_mode == \"transcription + translation\":\n",
				"\ttask = \"translate\"\n",
				"elif translation_mode == \"transcription only\":\n",
				"\ttask = \"transcribe\"\n",
				"else:\n",
				"\traise ValueError(\"Invalid translation mode\")\n",
				"\n",
				"if not os.path.exists(audio_path):\n",
				"\ttry:\n",
				"\t\taudio_path = uploaded_file\n",
				"\t\tif not os.path.exists(audio_path):\n",
				"\t\t\traise ValueError(\"Input audio not found. Is your audio_path correct?\")\n",
				"\texcept:\n",
				"\t\traise ValueError(\"Input audio not found. Did you upload a file?\")\n",
				"\n",
				"if os.path.isfile(audio_path):\n",
				"\tprint(audio_path)\n",
				"\tmy_transcribe_func(audio_path, task, language)\n",
				"elif os.path.isdir(audio_path):\n",
				"\tfor root, dirs, files in os.walk(audio_path):\n",
				"\t\taudio_files = filter(lambda filename: os.path.splitext(filename)[1].lower() in MEDIA_EXT, files)\n",
				"\t\tfor filename in audio_files:\n",
				"\t\t\tfilepath = os.path.join(root, filename)\n",
				"\t\t\tprint(filepath)\n",
				"\t\t\tmy_transcribe_func(filepath, task, language)\n",
				"else:\n",
				"\traise ValueError(\"cannot open audio path\")"
			]
		}
	],
	"metadata": {
		"accelerator": "GPU",
		"colab": {
			"private_outputs": true,
			"provenance": []
		},
		"kernelspec": {
			"display_name": "Python 3",
			"name": "python3"
		},
		"language_info": {
			"name": "python"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 0
}
